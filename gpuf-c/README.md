# ğŸš€ GPUFabric Client (gpuf-c)

High-performance distributed LLM inference client with multi-engine and cross-platform support.

## ğŸ“– Documentation

For complete documentation, see [docs/README.md](docs/README.md)

### ğŸ¯ Quick Links
- [Android Integration Guide](docs/mobile/ANDROID_DEVELOPMENT_GUIDE.md)
- [Build Guide](docs/BUILD_GUIDE.md)  
- [API Reference](docs/api/API_REFERENCE.md)
- [Examples](examples/README.md)

## ğŸš€ Quick Start

```bash
# Build
cargo build --release

# Android SDK
cargo ndk -t arm64-v8a build --release --features android

# Run examples
cargo run --example test_client_sdk
```

## âœ¨ Key Features

- ğŸ¤– Multi-engine support (llama.cpp, Ollama, VLLM)
- ğŸ“± Cross-platform support (Android, Windows, Linux, macOS)
- âš¡ GPU acceleration (Vulkan, CUDA, Metal)
- ğŸŒ Distributed inference
- ğŸ”Œ OpenAI-compatible API

---

**See [docs/README.md](docs/README.md) for complete documentation**
