// å®Œæ•´çš„ llama.cpp ä½¿ç”¨ç¤ºä¾‹
use gpuf_c::llama_engine::{LlamaEngine};
use std::path::Path;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ðŸš€ GPUFabric Llama.cpp ä½¿ç”¨ç¤ºä¾‹");
    
    // 1. æ£€æŸ¥ Android å…¼å®¹æ€§
    #[cfg(target_os = "android")]
    {
        use gpuf_c::android_compat;
        
        let api_level = android_compat::get_android_api_level();
        let supports_posix = android_compat::supports_posix_madvise();
        let llama_available = android_compat::is_llama_available();
        
        println!("ðŸ“± Android API Level: {}", api_level);
        println!("âœ… POSIX madvise æ”¯æŒ: {}", supports_posix);
        println!("ðŸ”§ Llama.cpp å¯ç”¨: {}", llama_available);
        
        if !llama_available {
            return Err("Llama.cpp ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æž„å»ºé…ç½®".into());
        }
    }
    
    // 2. æ˜¾ç¤º llama.cpp ç‰ˆæœ¬
    #[cfg(target_os = "android")]
    {
        let version = android_compat::get_llama_version();
        println!("ðŸ“¦ Llama.cpp ç‰ˆæœ¬: {}", version);
    }
    
    // 3. åˆå§‹åŒ–å¼•æ“Ž
    println!("ðŸ”§ æ­£åœ¨åˆå§‹åŒ– LlamaEngine...");
    
    // æ¨¡åž‹è·¯å¾„ - åœ¨å®žé™…ä½¿ç”¨ä¸­ï¼Œè¿™åº”è¯¥æ˜¯ä½ çš„ GGUF æ¨¡åž‹æ–‡ä»¶è·¯å¾„
    let model_path = "/data/local/tmp/model.gguf";
    
    // å¦‚æžœæ¨¡åž‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿå¼•æ“Ž
    let engine = if Path::new(model_path).exists() {
        println!("ðŸ“ æ‰¾åˆ°æ¨¡åž‹æ–‡ä»¶: {}", model_path);
        LlamaEngine::new(model_path).await?
    } else {
        println!("âš ï¸  æ¨¡åž‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼");
        return simulate_usage();
    };
    
    // 4. èŽ·å–å¼•æ“Žä¿¡æ¯
    let info = engine.get_info();
    println!("ðŸ“Š å¼•æ“Žä¿¡æ¯:");
    println!("  - API Level: {}", info.api_level);
    println!("  - MMap æ”¯æŒ: {}", info.supports_mmap);
    println!("  - POSIX madvise æ”¯æŒ: {}", info.supports_posix_madvise);
    println!("  - æ¨¡åž‹å·²åŠ è½½: {}", info.model_loaded);
    
    // 5. ç”Ÿæˆæ–‡æœ¬ç¤ºä¾‹
    println!("\nðŸŽ¯ å¼€å§‹ç”Ÿæˆæ–‡æœ¬...");
    let prompt = "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½";
    
    match engine.generate(prompt, 100).await {
        Ok(response) => {
            println!("âœ… ç”ŸæˆæˆåŠŸ:");
            println!("ðŸ“ {}", response);
        }
        Err(e) => {
            println!("âŒ ç”Ÿæˆå¤±è´¥: {}", e);
        }
    }
    
    println!("\nðŸŽ‰ ç¤ºä¾‹å®Œæˆ!");
    Ok(())
}

// æ¨¡æ‹Ÿä½¿ç”¨å‡½æ•°ï¼ˆå½“æ²¡æœ‰çœŸå®žæ¨¡åž‹æ—¶ï¼‰
fn simulate_usage() -> Result<(), Box<dyn std::error::Error>> {
    println!("ðŸ”„ æ¨¡æ‹Ÿæ¨¡å¼:");
    println!("  - åœ¨å®žé™…ä½¿ç”¨ä¸­ï¼Œè¯·æä¾›æœ‰æ•ˆçš„ GGUF æ¨¡åž‹æ–‡ä»¶");
    println!("  - æ¨¡åž‹æ–‡ä»¶åº”è¯¥æ”¾ç½®åœ¨åº”ç”¨å¯è®¿é—®çš„ç›®å½•ä¸­");
    println!("  - æŽ¨èä½¿ç”¨ Android 10+ (API 29+) ä»¥èŽ·å¾—æœ€ä½³æ€§èƒ½");
    
    Ok(())
}

// JNI ä½¿ç”¨ç¤ºä¾‹ï¼ˆåœ¨ Android åº”ç”¨ä¸­ï¼‰
#[cfg(target_os = "android")]
#[no_mangle]
pub extern "C" fn Java_com_pocketpal_LlamaExample_nativeTest(
    env: jni::JNIEnv,
    _class: jni::objects::JClass,
    model_path: jni::objects::JString,
) -> jni::sys::jstring {
    use jni::sys::{jstring, JNI_TRUE};
    
    // èŽ·å–æ¨¡åž‹è·¯å¾„
    let model_path_str = match env.get_string(model_path) {
        Ok(s) => s,
        Err(_) => {
            return env.new_string("Error: Invalid model path").unwrap().into_inner();
        }
    };
    
    // åœ¨å®žé™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šåˆ›å»ºå¹¶ä½¿ç”¨ LlamaEngine
    let result = format!("Model path received: {}", model_path_str.to_string_lossy());
    
    // è¿”å›žç»“æžœ
    env.new_string(result).unwrap().into_inner()
}
